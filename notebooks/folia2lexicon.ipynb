{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "\n",
    "* Add relationships between models (should make processing an xml file faster)\n",
    "* Use sessions better: https://docs.sqlalchemy.org/en/latest/orm/session_basics.html#when-do-i-construct-a-session-when-do-i-commit-it-and-when-do-i-close-it\n",
    "* Add multiple documents\n",
    "* Extract vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'lexicon_test'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "engine = create_engine(\"mysql://{}:{}@localhost/{}\".format(os.environ['user'], \n",
    "                                                           os.environ['password'], \n",
    "                                                           os.environ['dbname']))\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexicon_schema import AnalyzedWordform, Document, Lemmata, TokenAttestation, Wordform, Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tables\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "\n",
    "# Get table information\n",
    "print(inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def process_folia(fname, session):\n",
    "    # Extract document properties and insert into database (store document id)\n",
    "    context = etree.iterparse(fname, events=('start', ), tag=('{http://ilk.uvt.nl/folia}FoLiA'))\n",
    "    for event, elem in context:\n",
    "        doc_id = elem.attrib['{http://www.w3.org/XML/1998/namespace}id']\n",
    "        break\n",
    "        \n",
    "    doc = Document(doc_id)\n",
    "    session.add(doc)\n",
    "    session.commit()\n",
    "    \n",
    "    # Extract the words\n",
    "    context = etree.iterparse(fname, events=('end', ), tag=('{http://ilk.uvt.nl/folia}w'))\n",
    "    for event, elem in tqdm(context):\n",
    "        if elem.attrib['class'] == \"WORD\":\n",
    "            for child in elem.getchildren():\n",
    "                #print(child.tag)\n",
    "                tag = child.tag\n",
    "                if tag == '{http://ilk.uvt.nl/folia}t':\n",
    "                    wordform = child.text\n",
    "                elif tag == '{http://ilk.uvt.nl/folia}pos':\n",
    "                    postag = child.attrib['head']\n",
    "                elif tag == '{http://ilk.uvt.nl/folia}lemma':\n",
    "                    lemma = child.attrib['class']\n",
    "            \n",
    "            # add wordform if necessary\n",
    "            wf = session.query(Wordform).filter(Wordform.wordform==wordform).first()\n",
    "            if wf is None:\n",
    "                #print('Adding wordform:', wordform)\n",
    "                wf = Wordform(wordform)\n",
    "                session.add(wf)\n",
    "                session.commit()\n",
    "            wf_id = wf.wordform_id\n",
    "            \n",
    "            # add lemma if necessary\n",
    "            lm = session.query(Lemmata).filter(Lemmata.modern_lemma==lemma, \n",
    "                                               Lemmata.lemma_part_of_speech==postag).first()\n",
    "            if lm is None:\n",
    "                #print('Adding lemma:', lemma)\n",
    "                lm = Lemmata(lemma, postag)\n",
    "                session.add(lm)\n",
    "                session.commit()\n",
    "            lm_id = lm.lemma_id\n",
    "            \n",
    "            # add analyzed_wordform\n",
    "            awf = AnalyzedWordform(postag, lm_id, wf_id)\n",
    "            session.add(awf)\n",
    "            session.commit()\n",
    "            \n",
    "            # add token_attestation\n",
    "            ta = TokenAttestation(awf.analyzed_wordform_id, doc.document_id)\n",
    "        \n",
    "        # make iteration over context fast and consume less memory\n",
    "        #https://www.ibm.com/developerworks/xml/library/x-hiperfparse\n",
    "        elem.clear()\n",
    "        while elem.getprevious() is not None:\n",
    "            del elem.getparent()[0]\n",
    "        \n",
    "        session.commit()\n",
    "\n",
    "session = Session()\n",
    "process_folia('/home/jvdzwaan/data/embem/folia/original/alew001besl01_01.xml', session)\n",
    "session.commit()\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge_db():\n",
    "    session = Session()\n",
    "    session.query(AnalyzedWordform).delete()\n",
    "    session.query(Document).delete()\n",
    "    session.query(Lemmata).delete()\n",
    "    session.query(TokenAttestation).delete()\n",
    "    session.query(Wordform).delete()\n",
    "    session.commit()\n",
    "    session.close()\n",
    "        \n",
    "purge_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy_utils.functions import drop_database\n",
    "\n",
    "drop_database(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "wf = Wordform('Opdragt')\n",
    "session.add(wf)\n",
    "session.commit()\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "res = session.query(Wordform).filter(Wordform.wordform==\"van\").first()\n",
    "session.close()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.wordform_id, res.wordform_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "res = session.query(Wordform).delete()\n",
    "session.commit()\n",
    "session.close()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "res = session.query(Wordform).filter(Wordform.wordform_id==8786).first()\n",
    "session.close()\n",
    "print(res.wordform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "res = pd.read_sql(session.query(AnalyzedWordform).statement,session.bind)\n",
    "session.close()\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
