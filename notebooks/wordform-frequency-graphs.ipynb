{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s [%(process)d] %(levelname)-8s \"\n",
    "                    \"%(name)s,%(lineno)s\\t%(message)s\")\n",
    "logging.getLogger().setLevel('DEBUG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat'\n",
    "#db_name = 'ticclat_test'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat_schema import corpusId_x_documentId, TextAttestation, Lexicon, Wordform, Anahash, Document, Corpus, WordformLink, WordformLinkSource, lexical_source_wordform\n",
    "\n",
    "from ticclat.dbutils import get_session, session_scope\n",
    "\n",
    "Session = get_session(os.environ['user'], os.environ['password'], os.environ['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.queries import wfs_min_num_lexica\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    r = wfs_min_num_lexica(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in r:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.queries import count_unique_wfs_in_corpus\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    r = count_unique_wfs_in_corpus(session, corpus_name='SoNaR-500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.queries import wordform_in_corpus_over_time\n",
    "\n",
    "def wf_frequencies(session, wf, corpus_name):\n",
    "    r = wordform_in_corpus_over_time(session, wf=word, corpus_name=corpus_name)\n",
    "\n",
    "    records = [row for row in r.fetchall()]\n",
    "    df = pd.DataFrame.from_records(records, columns=['wordform_id', 'wordform', 'pub_year', 'document_frequency', 'term_frequency'])\n",
    "    df.sort_values(by=['pub_year'], inplace=True)\n",
    "    df['term_frequency'] = df['term_frequency'].astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "word = 'regeering'\n",
    "corpus_name='Staten Generaal Digitaal'\n",
    "with session_scope(Session) as session:\n",
    "    df = wf_frequencies(session, word, corpus_name)\n",
    "df.plot(x='pub_year', y=['term_frequency', 'document_frequency'], figsize=(10,5), grid=True, title=f'\\\"{word}\\\" in {corpus_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'regering'\n",
    "corpus_name='Staten Generaal Digitaal'\n",
    "with session_scope(Session) as session:\n",
    "    df2 = wf_frequencies(session, word, corpus_name)\n",
    "df2.plot(x='pub_year', y=['term_frequency', 'document_frequency'], figsize=(10,5), grid=True, title=f'\\\"{word}\\\" in {corpus_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.queries import wordform_in_corpora\n",
    "\n",
    "word = 'regering'\n",
    "corpus_name='Staten Generaal Digitaal'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    r = wordform_in_corpora(session, wf=word)\n",
    "records = [row for row in r]\n",
    "df = pd.DataFrame.from_records(records, columns=['wordform_id', 'wordform', 'pub_year', 'document_frequency', 'term_frequency'])\n",
    "df.sort_values(by=['pub_year'], inplace=True)\n",
    "df['term_frequency'] = df['term_frequency'].astype(int)\n",
    "df.plot(x='pub_year', y=['term_frequency', 'document_frequency'], figsize=(10,5), grid=True, title=f'\\\"{word}\\\" in {corpus_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [row for row in r]\n",
    "df = pd.DataFrame.from_records(records)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import select, text\n",
    "from sqlalchemy.sql import func, distinct, and_, desc\n",
    "\n",
    "def wordform_in_corpora_over_time(session, wf):\n",
    "    \"\"\"Given a wordform, and a corpus, return word frequencies over time.\n",
    "\n",
    "    Gives both the term frequency and document frequency.\n",
    "    \"\"\"\n",
    "    q = select([Corpus.name, Document.pub_year,\n",
    "                func.count(Document.document_id).label('document_frequency'),\n",
    "                func.sum(TextAttestation.frequency).label('term_frequency'),\n",
    "                func.sum(Document.word_count).label('num_words')]) \\\n",
    "        .select_from(Corpus.__table__.join(corpusId_x_documentId,\n",
    "                                           Corpus.corpus_id ==\n",
    "                                           corpusId_x_documentId.c.corpus_id)\n",
    "                     .join(Document,\n",
    "                           Document.document_id ==\n",
    "                           corpusId_x_documentId.c.document_id)\n",
    "                     .join(TextAttestation).join(Wordform)) \\\n",
    "        .where(Wordform.wordform == wf) \\\n",
    "        .group_by(Corpus.name, Document.pub_year, Wordform.wordform, Wordform.wordform_id)\n",
    "\n",
    "    print(f'Executing query:\\n{q}')\n",
    "\n",
    "    return pd.read_sql(q, session.connection())\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    r = wordform_in_corpora_over_time(session, wf='regering')\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['normalized_term_frequency'] = r['term_frequency'] / r['num_words'] * 100.0\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from IPython.display import HTML\n",
    "hv.notebook_extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = hv.Dataset(hv.Table(r[['name', 'pub_year', 'normalized_term_frequency']]), ['name', 'pub_year'], ['normalized_term_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to(hv.Curve, 'pub_year', 'normalized_term_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndoverlay = data.select().to(hv.Curve, 'pub_year', 'normalized_term_frequency').overlay('name')\n",
    "ndoverlay"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
