{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat_test'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.dbutils import create_ticclat_database\n",
    "\n",
    "create_ticclat_database(delete_existing=True, dbname=os.environ['dbname'], user=os.environ['user'], passwd=os.environ['password'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash\n",
    "\n",
    "from ticclat.dbutils import get_session, session_scope\n",
    "\n",
    "Session = get_session(os.environ['user'], os.environ['password'], os.environ['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add two lexicons\n",
    "\n",
    "from ticclat.dbutils import add_lexicon\n",
    "\n",
    "name1 = 'l1'\n",
    "wfs1 = pd.DataFrame()\n",
    "wfs1['wordform'] = ['wf1', 'wf2', 'wf3']\n",
    "\n",
    "name2 = 'l2'\n",
    "wfs2 = pd.DataFrame()\n",
    "wfs2['wordform'] = ['wf2', 'wf3', 'wf4']\n",
    "\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    lex1 = add_lexicon(session, lexicon_name=name1, vocabulary=True, wfs=wfs1)\n",
    "    lex2 = add_lexicon(session, lexicon_name=name2, vocabulary=True, wfs=wfs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a corpus\n",
    "from ticclat.tokenize import terms_documents_matrix_counters\n",
    "from ticclat.sacoreutils import add_corpus_core\n",
    "\n",
    "name = 'corpus1'\n",
    "\n",
    "documents = [['wf1', 'wf2'], ['wf2', 'wf3'], ['wf4', 'wf5', 'wf6']]\n",
    "\n",
    "corpus_matrix, vectorizer = terms_documents_matrix_counters(documents)\n",
    "print(corpus_matrix.shape)\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "metadata = pd.DataFrame()\n",
    "metadata['title'] = ['doc1', 'doc2', 'doc3']\n",
    "metadata['pub_year'] = [2018, 2011, 2019]\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    add_corpus_core(session, corpus_matrix, vectorizer, name, metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another corpus\n",
    "from ticclat.tokenize import terms_documents_matrix_counters\n",
    "from ticclat.sacoreutils import add_corpus_core\n",
    "\n",
    "name = 'corpus2'\n",
    "\n",
    "documents = [['wf2', 'wf5'], ['wf4', 'wf5', 'wf6']]\n",
    "\n",
    "corpus_matrix, vectorizer = terms_documents_matrix_counters(documents)\n",
    "print(corpus_matrix.shape)\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "metadata = pd.DataFrame()\n",
    "metadata['title'] = ['doc4', 'doc5']\n",
    "metadata['pub_year'] = [2002, 2011]\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    add_corpus_core(session, corpus_matrix, vectorizer, name, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add another corpus\n",
    "from ticclat.tokenize import terms_documents_matrix_counters\n",
    "from ticclat.sacoreutils import add_corpus_core\n",
    "\n",
    "name = 'corpus3'\n",
    "\n",
    "documents = [['wf2', 'wf5'], ['wf2', 'wf3', 'wf6'], ['wf2']]\n",
    "\n",
    "corpus_matrix, vectorizer = terms_documents_matrix_counters(documents)\n",
    "print(corpus_matrix.shape)\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "metadata = pd.DataFrame()\n",
    "metadata['title'] = ['doc6', 'doc7', 'doc8']\n",
    "metadata['pub_year'] = [2002, 2011, 2018]\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    add_corpus_core(session, corpus_matrix, vectorizer, name, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Corpus, Document, TextAttestation\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    print('number of wordforms:', session.query(Wordform).count())\n",
    "    print('number of lexica:', session.query(Lexicon).count())\n",
    "    print('number of corpora:', session.query(Corpus).count())\n",
    "    print('number of documents:', session.query(Document).count())\n",
    "    print('number of text attestations:', session.query(TextAttestation).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
