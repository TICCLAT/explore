{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()\n",
    "            \n",
    "os.environ['lexicon_name'] = os.environ['dbname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import textwrap\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def do_query(query):\n",
    "    cn = MySQLdb.connect(host='localhost', \n",
    "                         port=3306,\n",
    "                         user=os.environ.get('user'), \n",
    "                         passwd=os.environ.get('password'),\n",
    "                         db=os.environ.get('dbname'))\n",
    "    df_mysql = pd.read_sql(query, con=cn)    \n",
    "    cn.close()\n",
    "    # deduplicate columns\n",
    "    df_mysql = df_mysql.loc[:,~df_mysql.columns.duplicated()]\n",
    "    return df_mysql\n",
    "\n",
    "tables = do_query('SHOW TABLES;')\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs = do_query('SELECT * FROM wordforms;')\n",
    "wfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wfs.shape)\n",
    "print(len(wfs['wordform'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some duplicate wordforms. This is a violation of the uniqueness constraint on wordform. So, we need to filter the dataframe before adding it to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs = wfs.drop_duplicates(subset='wordform')\n",
    "wfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as frequency list for ticcl\n",
    "wfs['freq'] = 1\n",
    "wfs.head()\n",
    "wfs.to_csv(os.environ['lexicon_name'], sep='\\t', header=False, index=False, columns=['wordform', 'freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "engine = create_engine(\"mysql://{}:{}@localhost/{}?charset=utf8mb4\".format(os.environ['user'], \n",
    "                                                                        os.environ['password'], \n",
    "                                                                        os.environ['dbname']))\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat import Lexicon, Wordform, Anahash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://docs.sqlalchemy.org/en/latest/orm/session_basics.html\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def session_scope():\n",
    "    \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n",
    "    session = Session()\n",
    "    try:\n",
    "        yield session\n",
    "        session.commit()\n",
    "    except:\n",
    "        session.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session_scope() as session:\n",
    "    lex = Lexicon(lexicon_name=os.environ['lexicon_name'])\n",
    "    wf = Wordform(wordform_id=528954, \n",
    "                  wordform='tuyld',\n",
    "                  has_analysis=False,\n",
    "                  wordform_lowercase='tuyld')\n",
    "    wf.lexica.append(lex)\n",
    "    session.add(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session_scope() as session:\n",
    "    print('number of wordforms:', session.query(Wordform).count())\n",
    "    print('number of lexica:', session.query(Lexicon).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def create_wf(row, lex, session):\n",
    "    #print(row['wordform_id'])\n",
    "    wf = Wordform(wordform_id=row['wordform_id'], \n",
    "                  wordform=row['wordform'],\n",
    "                  has_analysis=False,\n",
    "                  wordform_lowercase=row['wordform_lowercase'])\n",
    "    wf.lexica.append(lex)\n",
    "    session.add(wf)\n",
    "    #print(wf)\n",
    "    #session.commit()\n",
    "\n",
    "with session_scope() as session:\n",
    "    lex = Lexicon(lexicon_name=os.environ['lexicon_name'])\n",
    "    # We can't use apply, because apply calls the function twice for the first row, see\n",
    "    # http://pandas.pydata.org/pandas-docs/stable/groupby.html#flexible-apply\n",
    "    for idx, row in wfs.iterrows():\n",
    "        #print(idx)\n",
    "        create_wf(row, lex, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should give a single result!\n",
    "with session_scope() as session:\n",
    "    data = session.query(Wordform).filter(Wordform.wordform == 'dóór').all()\n",
    "    for wf in data:\n",
    "        print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = pd.read_csv('{}.clean.list'.format(os.environ['lexicon_name']), sep='\\t', header=None)\n",
    "hashes.columns = ['wordform', 'hash']\n",
    "print(hashes.shape)\n",
    "hashes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with session_scope() as session:\n",
    "    for idx, row in hashes.iterrows():\n",
    "        wf = session.query(Wordform).filter(Wordform.wordform == row['wordform']).first()\n",
    "        if wf is None:\n",
    "            print(row['wordform'])\n",
    "        else:\n",
    "            h = Anahash(anahash=row['hash'])\n",
    "            session.add(h)\n",
    "            wf.anahash = h    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many wordforms cannot be found in the database. Maybe not clean the frequency list?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
