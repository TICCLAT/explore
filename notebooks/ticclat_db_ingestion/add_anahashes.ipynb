{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('../ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()\n",
    "            \n",
    "os.environ['lexicon_name'] = os.environ['dbname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat import Lexicon, Wordform, Anahash\n",
    "\n",
    "from ticclat.dbutils import get_session, session_scope\n",
    "\n",
    "Session = get_session(os.environ['user'], os.environ['password'], os.environ['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.dbutils import get_word_frequency_df\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    df = get_word_frequency_df(session)\n",
    "\n",
    "hash_file = 'vocabulary'\n",
    "\n",
    "print(df.head())\n",
    "df.to_csv(hash_file, sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sh\n",
    "\n",
    "alphabet_file = '/home/jvdzwaan/data/ticclat/ticcl/nld.aspell.dict.lc.chars'\n",
    "\n",
    "res = sh.TICCL_anahash(['--list', '--alph', alphabet_file, hash_file])\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anahashes_file = 'vocabulary.list'\n",
    "\n",
    "anahashes = pd.read_csv(anahashes_file, sep='\\t', header=None, names=['anahash'], \n",
    "                        index_col=0, keep_default_na=False)  # make sure word 'null' is read as string and not NaN\n",
    "anahashes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ticclat.dbutils import get_word_frequency_df\n",
    "from ticclat.utils import anahash_df\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    df = get_word_frequency_df(session)\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "ah = anahash_df(df, alphabet_file)\n",
    "print(ah.shape)\n",
    "ah.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ticclat.dbutils import bulk_add_anahashes\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    total = bulk_add_anahashes(session, ah)\n",
    "print('num of anahashes added:', total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ticclat.dbutils import connect_anahases_to_wordforms\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    total = connect_anahases_to_wordforms(session, anahashes)\n",
    "print('num of wordforms connected to anahashes:', total)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
