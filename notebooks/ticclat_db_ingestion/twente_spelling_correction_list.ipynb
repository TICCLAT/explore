{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('../ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# read error data\n",
    "import re\n",
    "\n",
    "def parse_line(line):\n",
    "    # the wordform starts with *\n",
    "    # corrections start with # (there can be multiple) and end with whitspace or ~\n",
    "    # example text start with ~\n",
    "    # 'rules' start with <space>[\n",
    "    \n",
    "    # get the wordform\n",
    "    wf_regex = r'^\\*(?P<wf>.+?)[\\t#]'\n",
    "    m = re.match(wf_regex, line)\n",
    "    wf = m.group('wf')\n",
    "    # Wordforms need to be stripped! \n",
    "    # Whitespace before or after wordforms also leads to duplicate entries in the database.\n",
    "    wf = wf.strip()\n",
    "\n",
    "    # get example text (and remove it)\n",
    "    ex_regex = r'~.+~?'\n",
    "    line = re.sub(ex_regex, '', line)\n",
    "    \n",
    "    # remove 'rule'\n",
    "    rule_regex = r'\\[EA?XAMPL: .+\\]'\n",
    "    line = re.sub(rule_regex, '', line)\n",
    "        \n",
    "    # get the corrections\n",
    "    corrections = []\n",
    "    corr_regex = r'#(?P<corr>.+)'\n",
    "    m = re.search(corr_regex, line)\n",
    "    if m:\n",
    "        # Wordforms need to be stripped! \n",
    "        # Whitespace before or after wordforms also leads to duplicate entries in the database.\n",
    "        corrections = [c.strip().replace('\\t', '') for c in m.group('corr').split('#') if c != '' and len(c) < 100] \n",
    "\n",
    "    return wf, corrections\n",
    "\n",
    "corrections = []\n",
    "\n",
    "# File is in windows-1252 encoding and needs to be converted to utf-8\n",
    "in_file = '/home/jvdzwaan/Downloads/TWENTE.noxml.2002.sq.clean.norm.tok.sortu.unifrq.LC.noapekrol.allasterisk.12.withcorrections.12186.txt'\n",
    "\n",
    "num_lines = 0\n",
    "with open(in_file) as f:\n",
    "    for line in f:\n",
    "        num_lines += 1\n",
    "        #print(repr(line))\n",
    "        wf, corr = parse_line(line)\n",
    "        if wf is not None:\n",
    "            for c in corr:\n",
    "                corrections.append({'wf': wf, 'corr': c})\n",
    "        #else:\n",
    "        #    print(line)\n",
    "        \n",
    "data = pd.DataFrame(corrections)\n",
    "print(num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_line('*variëiten\t1#1#variëteiten\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_line('*toestemmignbesluit#toestemmingenbesluit\t1\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wf'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MySQLdb\n",
    "import textwrap\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def do_query(query):\n",
    "    cn = MySQLdb.connect(host='localhost', \n",
    "                         port=3306,\n",
    "                         user=os.environ.get('user'), \n",
    "                         passwd=os.environ.get('password'),\n",
    "                         db=os.environ.get('dbname'))\n",
    "    df_mysql = pd.read_sql(query, con=cn)    \n",
    "    cn.close()\n",
    "    # deduplicate columns\n",
    "    df_mysql = df_mysql.loc[:,~df_mysql.columns.duplicated()]\n",
    "    return df_mysql\n",
    "\n",
    "tables = do_query('SHOW TABLES;')\n",
    "#tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordforms = do_query('SELECT * FROM wordforms;')\n",
    "wordforms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_wfs = set(wordforms['wordform'])\n",
    "error_wfs = set(data['corr'])\n",
    "\n",
    "new_words = error_wfs.difference(lexicon_wfs)\n",
    "print(len(new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edlib\n",
    "\n",
    "data['ed'] = data.apply(lambda row: edlib.align(row['wf'], row['corr'])['editDistance'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ed'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ed'].hist(bins=50, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('ed > 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many corrections per wordform?\n",
    "data['one'] = 1\n",
    "d = data.groupby('wf').sum()\n",
    "d[d['one'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add spelling correction list to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash\n",
    "\n",
    "from ticclat.dbutils import get_session, session_scope\n",
    "\n",
    "Session = get_session(os.environ['user'], os.environ['password'], os.environ['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs = pd.DataFrame()\n",
    "wfs['wordform'] = pd.concat([data['corr'], data['wf']])\n",
    "wfs = wfs.drop_duplicates(subset='wordform')\n",
    "wfs['has_analysis'] = False\n",
    "wfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs['wordform'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from ticclat.dbutils import add_lexicon\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    add_lexicon(session, 'Twente spelling correction list', wfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add the links between the words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    for idx, row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        #print(row['wf'], row['corr'])\n",
    "        wf = session.query(Wordform).filter(Wordform.wordform == row['wf']).first()\n",
    "        corr = session.query(Wordform).filter(Wordform.wordform == row['corr']).first()\n",
    "        #print(wf.wordform_id, corr.wordform_id)\n",
    "        wf.links.append(corr)\n",
    "        corr.links.append(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session_scope(Session) as session:\n",
    "    for idx, row in data.head().iterrows():\n",
    "        print(row['wf'])\n",
    "        wf = session.query(Wordform).filter(Wordform.wordform == row['wf']).first()\n",
    "        print(wf, [str(w) for w in wf.links])\n",
    "        corr = session.query(Wordform).filter(Wordform.wordform == row['corr']).first()\n",
    "        print(corr, [str(w) for w in corr.links])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how to add the link to the lexicon to the relation between wordforms?\n",
    "\n",
    "https://docs.sqlalchemy.org/en/latest/orm/basic_relationships.html#many-to-many"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
