{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('../ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash\n",
    "\n",
    "from ticclat.dbutils import get_session, session_scope\n",
    "\n",
    "Session = get_session(os.environ['user'], os.environ['password'], os.environ['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import textacy\n",
    "\n",
    "wiki = '/home/jvdzwaan/data/tmp/nlwiki-10'\n",
    "\n",
    "c = textacy.Corpus(textacy.load_spacy('nl', disable=('parser', 'tagger')),\n",
    "               texts=textacy.io.read_text(wiki, lines=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = textacy.Vectorizer()\n",
    "doc_term_matrix = vectorizer.fit_transform(\n",
    "    (doc.to_terms_list(ngrams=1, named_entities=False, as_strings=True)for doc in c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.terms_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vectorizer.terms_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs = pd.DataFrame()\n",
    "wfs['wordform'] = vectorizer.terms_list\n",
    "wfs['has_analysis'] = False\n",
    "wfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs['wordform'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs['len'] = wfs.apply(lambda row: len(row['wordform']), axis=1)\n",
    "wfs['len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfs['len'].hist(bins=50, figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session_scope(Session) as session:\n",
    "    print('number of wordforms:', session.query(Wordform).count())\n",
    "    print('number of lexica:', session.query(Lexicon).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.dbutils import bulk_add_wordforms\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    bulk_add_wordforms(session, wfs, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ticclat.ticclat_schema import Corpus, Document\n",
    "\n",
    "# we know all wordforms in de documents are in the database.\n",
    "# Now we can add a document\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    # Create corpus\n",
    "    #corpus = Corpus(name='nlwiki-20190201-1000')\n",
    "    #session.add(corpus)\n",
    "    \n",
    "    # select wordforms from document\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_term_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from ticclat.ticclat_schema import Document, TextAttestation\n",
    "\n",
    "n = 1\n",
    "prev_i = 0\n",
    "words = []\n",
    "freqs = {}\n",
    "\n",
    "cx = doc_term_matrix.tocoo()    \n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    wf = vectorizer.id_to_term[j]\n",
    "    words.append(wf)\n",
    "    freqs[wf] = v\n",
    "    if i != prev_i:\n",
    "        prev_i = i\n",
    "        n += 1\n",
    "        \n",
    "        with session_scope(Session) as session:\n",
    "            q = session.query(Wordform)\n",
    "            result = q.filter(Wordform.wordform.in_(words)).all()\n",
    "                        \n",
    "            d = Document(word_count=sum(freqs.values()), pub_year=2019, language='nl')\n",
    "            session.add(d)\n",
    "            for wf in result:\n",
    "                #print(wf.wordform, freqs[wf.wordform])\n",
    "                ta = TextAttestation(ta_document=d, ta_wordform=wf, frequency=freqs[wf.wordform])\n",
    "                session.add(ta)\n",
    "        \n",
    "        words = []\n",
    "        freqs = {}\n",
    "        print('added', str(d))\n",
    "\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy.vsm.matrix_utils.get_term_freqs(doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlen = textacy.vsm.matrix_utils.get_doc_lengths(doc_term_matrix)\n",
    "print(dlen.shape)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
