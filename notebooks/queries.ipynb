{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s [%(process)d] %(levelname)-8s \"\n",
    "                    \"%(name)s,%(lineno)s\\t%(message)s\")\n",
    "logging.getLogger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db_name = 'ticclat'\n",
    "db_name = 'ticclat_test'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, WordformLink, WordformLinkSource, lexical_source_wordform\n",
    "\n",
    "from ticclat.dbutils import get_session, session_scope\n",
    "\n",
    "Session = get_session(os.environ['user'], os.environ['password'], os.environ['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# select wordforms that occur in at least 2 lexica\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    subq = select([Wordform, func.count('lexicon_id').label('num_lexicons')]).select_from(lexical_source_wordform.join(Wordform)) \\\n",
    "        .group_by(Wordform.wordform_id)\n",
    "    q = select(['*']).select_from(subq.alias()).where(text('num_lexicons >= 2'))\n",
    "    print(q)\n",
    "    \n",
    "    r = session.execute(q) #.filter(subq.c.num_lexica > 1)\n",
    "    for row in r.fetchall():\n",
    "        print(row)\n",
    "        print(row['wordform'], row['num_lexicons'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select wordforms that occur in at least 2 lexica that are vocabularies (so only contain correct wordforms)\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.sql import func\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    subq = select([Wordform, func.count('lexicon_id').label('num_lexicons')]).select_from(lexical_source_wordform.join(Wordform).join(Lexicon)) \\\n",
    "        .where(Lexicon.vocabulary == True).group_by(Wordform.wordform_id)\n",
    "    q = select(['*']).select_from(subq.alias()).where('num_lexicons > 1')\n",
    "    print(q)\n",
    "    \n",
    "    r = session.execute(q) #.filter(subq.c.num_lexica > 1)\n",
    "    for row in r.fetchall():\n",
    "        print(row)\n",
    "        print(row['wordform'], row['num_lexicons'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get all the wordforms in a corpus\n",
    "from sqlalchemy import select\n",
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, \\\n",
    "    WordformLink, WordformLinkSource, lexical_source_wordform, corpusId_x_documentId, \\\n",
    "    TextAttestation\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Wordform.wordform_id,Wordform.wordform, Corpus.name]).select_from(\n",
    "        Corpus.__table__.join(corpusId_x_documentId).join(Document).join(TextAttestation).join(Wordform)\n",
    "    ).distinct()\n",
    "    r = session.execute(q)\n",
    "    for wf in r:\n",
    "        print(wf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# count the unique wordforms\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.sql import func, distinct\n",
    "\n",
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, \\\n",
    "    WordformLink, WordformLinkSource, lexical_source_wordform, corpusId_x_documentId, \\\n",
    "    TextAttestation\n",
    "\n",
    "name = 'SoNaR-500'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([func.count(distinct(Wordform.wordform_id))]).select_from(\n",
    "        Corpus.__table__.join(corpusId_x_documentId).join(Document).join(TextAttestation).join(Wordform)\n",
    "    ).where(Corpus.name == name)\n",
    "    r = session.execute(q)\n",
    "    for wf in r:\n",
    "        print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the wordforms in a lexicon\n",
    "name = 'l2'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Wordform.wordform]).select_from(\n",
    "        Lexicon.__table__.join(lexical_source_wordform).join(Wordform)\n",
    "    ).where(Lexicon.lexicon_name == name)\n",
    "    r = session.execute(q)\n",
    "    for wf in r:\n",
    "        print(wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select wordforms that occur in a lexicon and corpus\n",
    "from sqlalchemy.sql import intersect, and_\n",
    "# mysql does not have intersect\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    x = Wordform.__table__.alias('x')\n",
    "    name1 = 'l2'\n",
    "    name2 = 'corpus1'\n",
    "    q1 = select([Wordform]).select_from(\n",
    "            Wordform.__table__.join(lexical_source_wordform).join(Lexicon).join(TextAttestation, TextAttestation.wordform_id==Wordform.wordform_id).join(Document).join(corpusId_x_documentId).join(Corpus)\n",
    "        ).where(and_(Lexicon.lexicon_name == name1, Corpus.name == name2)).distinct()\n",
    "    \n",
    "    print(q1)\n",
    "\n",
    "    \n",
    "    #y = Wordform.__table__.alias('y')\n",
    "    #name = 'corpus1'\n",
    "    #q2 = select([y]).select_from(\n",
    "    #        Corpus.__table__.join(corpusId_x_documentId).join(Document).join(TextAttestation).join(Wordform)\n",
    "    #    ).where(Corpus.name == name).distinct()\n",
    "    \n",
    "    #print(q1.join(TextAttestation, x.c.wordform_id == TextAttestation.wordform_id).join(Document).join(corpusId_x_documentId).join(Corpus))\n",
    "        \n",
    "    r = session.execute(q1).fetchall()\n",
    "    print(r)\n",
    "    #r = session.execute(q2).fetchall()\n",
    "    #print(r)\n",
    "    \n",
    "    #r = session.execute(intersect(q1, q2)).fetchall()\n",
    "    #print(r)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# (aantal) wordforms per document in bepaald corpus\n",
    "\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.sql import func, distinct\n",
    "\n",
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, \\\n",
    "    WordformLink, WordformLinkSource, lexical_source_wordform, corpusId_x_documentId, \\\n",
    "    TextAttestation\n",
    "\n",
    "corpus_name = 'corpus1'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Wordform, Document.title]) \\\n",
    "        .select_from(\n",
    "            Corpus.__table__.join(corpusId_x_documentId).join(Document)\n",
    "            .join(TextAttestation).join(Wordform)\n",
    "        ).where(Corpus.name == corpus_name).group_by(Document.title, Wordform.wordform_id)\n",
    "    r = session.execute(q).fetchall()\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# (aantal) wordforms per document in bepaald corpus\n",
    "\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.sql import func, distinct\n",
    "\n",
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, \\\n",
    "    WordformLink, WordformLinkSource, lexical_source_wordform, corpusId_x_documentId, \\\n",
    "    TextAttestation\n",
    "\n",
    "corpus_name = 'SoNaR-500'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Document.title, func.count(distinct(Wordform.wordform_id)).label('tot_freq')]) \\\n",
    "        .select_from(\n",
    "            Corpus.__table__.join(corpusId_x_documentId).join(Document)\n",
    "            .join(TextAttestation).join(Wordform)\n",
    "        ).where(Corpus.name == corpus_name).group_by(Document.title)\n",
    "    print(q)\n",
    "    wf_doc = pd.read_sql(q, session.bind)\n",
    "    #r = session.execute(q).fetchall()\n",
    "    #print(r)\n",
    "print(wf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_doc = wf_doc.set_index('title')\n",
    "wf_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# (aantal) wordforms per document in bepaald corpus en bepaald lexicon\n",
    "\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.sql import func, distinct, and_\n",
    "\n",
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, \\\n",
    "    WordformLink, WordformLinkSource, lexical_source_wordform, corpusId_x_documentId, \\\n",
    "    TextAttestation\n",
    "\n",
    "corpus_name = 'SoNaR-500'\n",
    "lexicon_name = 'GB95-05_002.csv.alltokens.utf8.nopunct'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Document.title, func.count(distinct(Wordform.wordform_id)).label('lexicon_freq')]) \\\n",
    "        .select_from(\n",
    "            Corpus.__table__.join(corpusId_x_documentId).join(Document)\n",
    "            .join(TextAttestation).join(Wordform).join(lexical_source_wordform).join(Lexicon)\n",
    "        ).where(and_(Corpus.name == corpus_name, Lexicon.lexicon_name == lexicon_name)).group_by(Document.title)\n",
    "    print(q)\n",
    "    wf_l_doc = pd.read_sql(q, session.bind)\n",
    "    #r = session.execute(q).fetchall()\n",
    "    #print(r)\n",
    "print(wf_l_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_l_doc = wf_l_doc.set_index('title')\n",
    "wf_l_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([wf_doc, wf_l_doc], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['%_lexicon_wordforms'] = data['lexicon_freq']/data['tot_freq']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(tabulate(data, headers=['text_type', '#wordforms', '#wordforms in GB1995/2005', '%overlap'], tablefmt=\"github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# lijst met lexicons en aantal woordvormen per lexicon\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.sql import func, distinct, and_\n",
    "\n",
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, \\\n",
    "    WordformLink, WordformLinkSource, lexical_source_wordform, corpusId_x_documentId, \\\n",
    "    TextAttestation\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Lexicon.lexicon_name, func.count(distinct(Wordform.wordform_id)).label('num_wordforms')]) \\\n",
    "        .select_from(\n",
    "            Wordform.__table__.join(lexical_source_wordform).join(Lexicon)\n",
    "        ).group_by(Lexicon.lexicon_name)\n",
    "    print(q)\n",
    "    r = session.execute(q).fetchall()\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# anahashes with number of wordforms\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.sql import func, desc\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    subq = select([Anahash, func.count('wordform_id').label('num_wf')]).select_from(Anahash.__table__.join(Wordform)) \\\n",
    "        .group_by(Anahash.anahash_id)\n",
    "    q = select(['*']).select_from(subq.alias()).where(text('num_wf > 1')).order_by(desc('num_wf'))\n",
    "    print(q)\n",
    "    \n",
    "    r = session.execute(q) #.filter(subq.c.num_lexica > 1)\n",
    "    for row in r.fetchall():\n",
    "        print(row)\n",
    "        break\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cf_file = '/home/jvdzwaan/data/ticclat/ticcl/nld.aspell.dict.c20.d2.confusion'\n",
    "\n",
    "cfs = []\n",
    "\n",
    "with open(cf_file) as f:\n",
    "    for line in f:\n",
    "        cf, _ = line.split('#')\n",
    "        cfs.append(int(cf))\n",
    "print(len(cfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# gegeven een woord, geef alle woorden in de db die 'dichtbij' zijn (1 character confusion verschil)\n",
    "\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.sql import func, desc\n",
    "\n",
    "word = 'koelkast'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Wordform, Anahash]).select_from(Wordform.__table__.join(Anahash)).where(Wordform.wordform == word)\n",
    "\n",
    "    r = session.execute(q)\n",
    "    wf = r.fetchone()\n",
    "    anahash = wf['anahash']\n",
    "    print(wf, anahash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "with session_scope(Session) as session:\n",
    "    for v in cfs:\n",
    "        av = anahash + v\n",
    "        q = select([Wordform, Anahash]).select_from(Wordform.__table__.join(Anahash)).where(Anahash.anahash == av)\n",
    "        for row in session.execute(q).fetchall():\n",
    "            results.append(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[343])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Given a wordform, give word frequencies per year (term frequency and document frequency)\n",
    "# Seems useful to optionally select a corpus or corpora\n",
    "from ticclat.ticclat_schema import TextAttestation, corpusId_x_documentId\n",
    "\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.sql import func, desc, and_\n",
    "\n",
    "word = 'wf2'\n",
    "corpus_name = 'corpus1'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Wordform.wordform_id, Wordform.wordform, Document.pub_year, func.count(Document.document_id).label('document_frequency'), func.sum(TextAttestation.frequency).label('term_frequency')]).select_from(\n",
    "        Corpus.__table__.join(corpusId_x_documentId, Corpus.corpus_id == corpusId_x_documentId.c.corpus_id).join(Document, Document.document_id == corpusId_x_documentId.c.document_id).join(TextAttestation).join(Wordform)\n",
    "    ).where(and_(Wordform.wordform == word, Corpus.name == corpus_name)).group_by(Document.pub_year, Wordform.wordform, Wordform.wordform_id)\n",
    "    #q = select(['wordform', 'name', func.sum('frequency').label('freq')]).select_from(subq.alias()).group_by('name')\n",
    "    print(q)\n",
    "    \n",
    "    r = session.execute(q)\n",
    "    for row in r.fetchall():\n",
    "        #print(row['name'], row['corpus_frequency'])\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Given a wordform, in what corpora does it occur, with what frequencies (term frequency and document frequency)\n",
    "\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy import text\n",
    "from sqlalchemy.sql import func, desc\n",
    "\n",
    "word = 'wf2'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Wordform.wordform_id,Wordform.wordform, Corpus.name, func.count(Document.document_id).label('document_frequency'), func.sum(TextAttestation.frequency).label('term_frequency')]).select_from(\n",
    "        Corpus.__table__.join(corpusId_x_documentId, Corpus.corpus_id == corpusId_x_documentId.c.corpus_id).join(Document, Document.document_id == corpusId_x_documentId.c.document_id).join(TextAttestation).join(Wordform)\n",
    "    ).where(Wordform.wordform == word).group_by(Corpus.name, Wordform.wordform, Wordform.wordform_id)\n",
    "    print(q)\n",
    "    \n",
    "    r = session.execute(q)\n",
    "    for row in r.fetchall():\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
