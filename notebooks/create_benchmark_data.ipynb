{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s [%(process)d] %(levelname)-8s \"\n",
    "                    \"%(name)s,%(lineno)s\\t%(message)s\")\n",
    "logging.getLogger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db_name = 'ticclat_benchmark'\n",
    "db_name = 'ticclat_wikipedia'\n",
    "#db_name = 'ticclat'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sqlalchemy_utils import database_exists\n",
    "\n",
    "from ticclat.ticclat_schema import Base\n",
    "\n",
    "engine = create_engine(\"mysql://{}:{}@localhost/{}?charset=utf8mb4\".format(os.environ['user'], \n",
    "                                                            os.environ['password'], \n",
    "                                                            os.environ['dbname']))\n",
    "\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "# create tables\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, WordformLink, WordformLinkSource, lexical_source_wordform\n",
    "\n",
    "from ticclat.dbutils import get_session, session_scope\n",
    "\n",
    "Session = get_session(os.environ['user'], os.environ['password'], os.environ['dbname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with session_scope(Session) as session:\n",
    "    print('number of wordforms:', session.query(Wordform).count())\n",
    "    print('number of lexica:', session.query(Lexicon).count())\n",
    "    print('number of documents:', session.query(Document).count())\n",
    "    print('number of corpora:', session.query(Corpus).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# select all wordforms\n",
    "from sqlalchemy import select\n",
    "from sqlalchemy.sql import func, distinct\n",
    "\n",
    "from ticclat.ticclat_schema import Lexicon, Wordform, Anahash, Document, Corpus, \\\n",
    "    WordformLink, WordformLinkSource, lexical_source_wordform, corpusId_x_documentId, \\\n",
    "    TextAttestation\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    q = select([Wordform])\n",
    "    r = session.execute(q)\n",
    "    for wf in r.fetchall():\n",
    "        vocabulary.append(wf['wordform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "with open('wikipedia_wordforms.pkl', 'wb') as f:\n",
    "    pickle.dump(vocabulary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pickle\n",
    "\n",
    "with open('wikipedia_wordforms.pkl', 'rb') as f:\n",
    "    vocabulary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create a benchmark database\n",
    "from ticclat.benchmark import ingest_corpora, ingest_lexica, ingest_linked_lexica\n",
    "from ticclat.dbutils import update_anahashes\n",
    "\n",
    "num_wordforms = 100000\n",
    "\n",
    "alphabet_file = '/home/jvdzwaan/data/ticclat/ticcl/nld.aspell.dict.lc.chars'\n",
    "\n",
    "with session_scope(Session) as session:\n",
    "    ingest_corpora(session, num_corpora=20, num_documents_min=50, num_documents_max=200,\n",
    "                   language='nl', year_min=2000, year_max=2005, num_tokens_min=25000,\n",
    "                   num_tokens_max=50000, vocabulary=vocabulary[:num_wordforms])\n",
    "    ingest_lexica(session, num_lexica=10, num_wf_min=10000, num_wf_max=25000, vocabulary=vocabulary[:num_wordforms])\n",
    "    ingest_linked_lexica(session, num_lexica=10, num_wf_min=10000, num_wf_max=25000,\n",
    "                         vocabulary=vocabulary[:num_wordforms])\n",
    "    update_anahashes(session, alphabet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do queries\n",
    "#\n",
    "# for single wordforms:\n",
    "# * Given a wordform, give word frequencies per year\n",
    "# * Given a wordform, in what corpora does it occur, with what frequencies\n",
    "# * Give me all word(forms) that are related to this word(form) -> what does related mean?\n",
    "#\n",
    "# aggregate over wordforms\n",
    "# * wordforms that occur in at least two lexicons\n",
    "# * wordforms that occur in at least two corpora\n",
    "# * list of lexicons and number of wordforms in lexicon\n",
    "# * list of corpora and number of wordforms in corpus\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
