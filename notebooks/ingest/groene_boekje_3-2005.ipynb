{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groene boekje part 3: 2005\n",
    "\n",
    "The first two Groene Boekje notebooks dealt with the wordforms and links between wordforms for the 1995 corpus only.\n",
    "\n",
    "This notebook we will try the developed methods on the 2005 version and see what blows up and how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ticclat.dbutils\n",
    "import ticclat.ticclat_schema\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "\n",
    "import ticclat.ingest.groene_boekje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read information to connect to the database and put it in environment variables\n",
    "import os\n",
    "with open('ENVVARS.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split('=')\n",
    "        if len(parts) == 2:\n",
    "            os.environ[parts[0]] = parts[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'ticclat'\n",
    "os.environ['dbname'] = db_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Groene Boekje data into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_basepath = \"/Users/pbos/projects/ticclat/data/GB/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB1914_path = GB_basepath + \"1914/22722-8.txt\"\n",
    "GB1995_path = GB_basepath + \"1995-2005/1995/GB95_002.csv\"\n",
    "GB2005_path = GB_basepath + \"1995-2005/2005/GB05_002.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb2005 = ticclat.ingest.groene_boekje.load_GB95(GB2005_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb2005.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's not quite right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB2005 = pd.read_csv(GB2005_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB2005.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot more columns this time. Let's vogel it out.\n",
    "\n",
    "First, there's an extra first column that seems to be some index, probably relating the entries to the 1995 table rows.\n",
    "\n",
    "The other extra columns all seem to be empty for the first set of entries, i.e. those in the range up to 200,000. It looks like these are the same words as in the 1995 version.\n",
    "\n",
    "After 200,000, the first columns are instead empty and only the latter columns are used. Maybe they are using a different categorization there. If so, it would probably make more sense to split the table in two.\n",
    "\n",
    "First let's check whether indeed the above statements are true:\n",
    "\n",
    "1. Up to 200,000, the last columns are empty.\n",
    "2. Up to 200,000 are the same words as in the 1995 version. N.B.: It doesn't actually really matter whether words were already in the 1995 version; if they're in 2005 as well, that's extra info that needs to be incorporated in the database (i.e. that the wordforms also occur in this lexicon).\n",
    "3. After 200,000 are new words.\n",
    "4. After 200,000 the first columns are empty.\n",
    "5. The columns after 200,000 are different from those before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB2005 = pd.read_csv(GB2005_path, sep=';', escapechar=\"\\\\\", index_col=0,\n",
    "                        names=[\"word\", \"syllables\", \"see also\", \"disambiguation\",\n",
    "                               \"grammatical tag\", \"article\",\n",
    "                               \"plural/past/attrib\", \"plural/past/attrib syllables\",\n",
    "                               \"diminu/compara/past plural\", \"diminu/compara/past plural syllables\",\n",
    "                               \"past perfect/superla\", \"past perfect/superla syllables\"]\n",
    "                              + [\"???\"] * 12  # 25 total columns, 12 of which unknown, 1 is the index column; so 12 known, 12 unknown...\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(df_GB2005.loc[:200000][col].dropna()) for col in df_GB2005.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so they aren't exactly empty, at all really. But this is because (as we'll see below, the words are actually repeated in those rows for the (supposedly) 1995 words.\n",
    "\n",
    "What about the first columns for the later words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(df_GB2005.loc[200000:][col].dropna()) for col in df_GB2005.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we are almost confirmed in our hypothesis...\n",
    "\n",
    "...except that the last two columns are present. This seems to be because three columns from the 1995 data are now removed: \"see also\", \"disambiguation\" and \"article\". That then leaves us with 9 known columns, 1 index column and 15 unknown ones. Judging from the numbers, the last four are some kind of special row, so probably the 9 columns after the first 9 are the same, but then for the 2005 set. Actually, there appears to be one mysterious number row in between the two sets of 9.\n",
    "\n",
    "... ok all nice speculation, let's just check the CSV file though, doing that below.\n",
    "\n",
    "First to check the rest of the above assumptions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB2005.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see immediately that the columns have been reordered and modified. We will just examine the CSV and use the correct order below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"word\", \"syllables\", \"grammatical tag\",\n",
    "         \"plural/past/attrib\", \"plural/past/attrib syllables\",\n",
    "         \"diminu/compara/past plural\", \"diminu/compara/past plural syllables\",\n",
    "         \"past perfect/superla\", \"past perfect/superla syllables\"]\n",
    "actual_names = [n + \" 95\" for n in names] \\\n",
    "               + [\"MYSTERIOUS NUMBERS\",] \\\n",
    "               + [n + \" 05\" for n in names[:3]] \\\n",
    "               + ['article'] \\\n",
    "               + [n + \" 05\" for n in names[3:]] \\\n",
    "               + [\"1st person present singular\", \"1st person present singular syllables\",\n",
    "                  \"2nd/3rd person present singular\", \"2nd/3rd person present singular syllables\"]\n",
    "df_GB2005 = pd.read_csv(GB2005_path, sep=';', escapechar=\"\\\\\", index_col=0, names=actual_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GB2005[~df_GB2005[\"MYSTERIOUS NUMBERS\"].isna()].sample(6)\n",
    "# df_GB2005.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peculiarities\n",
    "\n",
    "- Some inflections in the 05 columns of the 95 words contain `/schrappen/`, meaning \"scratch\". Probably this means they wanted to remove this inflection from the 2005 version for some reason.\n",
    "- The last four columns are new, but also used for some of the 95 words. These are first and second/third person present tense singular verb forms for loanwords (mostly from English).\n",
    "- I have no idea what the mysterious numbers stand for..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_GB1995[~df_GB1995[\"see also\"].isnull()].sample(10)\n",
    "# # df_GB1995[~df_GB1995[\"disambiguation\"].isnull()].sample(10)\n",
    "# df_GB1995[~df_GB1995[\"disambiguation\"].isnull() & df_GB1995[\"disambiguation\"].str.contains(' ')].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
